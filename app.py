# app.py
import streamlit as st
import pandas as pd
from pathlib import Path
from PIL import Image
import uuid
import io
from datetime import datetime
from zoneinfo import ZoneInfo
import requests
import base64

GITHUB_REPO   = st.secrets.get("GITHUB_REPO")
GITHUB_BRANCH = st.secrets.get("GITHUB_BRANCH", "main")
GITHUB_TOKEN  = st.secrets.get("GITHUB_TOKEN")  # ç§æœ‰/éœ€è¦å¯«å…¥æ™‚å»ºè­°è¨­å®š

def _gh_headers():
    headers = {"Accept": "application/vnd.github+json"}
    if GITHUB_TOKEN:
        headers["Authorization"] = f"Bearer {GITHUB_TOKEN}"
    return headers

def gh_read_csv(path_in_repo: str) -> pd.DataFrame:
    """å¾ GitHub raw è®€å– CSVã€‚"""
    if not GITHUB_REPO:
        raise RuntimeError("GITHUB_REPO æœªè¨­å®š")
    url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/{GITHUB_BRANCH}/{path_in_repo}"
    r = requests.get(url, timeout=15)
    r.raise_for_status()
    return pd.read_csv(io.BytesIO(r.content), dtype=str)

def gh_get_file_sha(path_in_repo: str):
    """å–å¾—æª”æ¡ˆç›®å‰çš„ SHAï¼ˆç”¨æ–¼æ›´æ–°ï¼‰ï¼Œä¸å­˜åœ¨å‰‡å›å‚³ Noneã€‚"""
    if not GITHUB_REPO:
        return None
    url = f"https://api.github.com/repos/{GITHUB_REPO}/contents/{path_in_repo}?ref={GITHUB_BRANCH}"
    r = requests.get(url, headers=_gh_headers(), timeout=15)
    if r.status_code == 200:
        try:
            return r.json().get("sha")
        except Exception:
            return None
    return None

def gh_upsert_file(path_in_repo: str, content_bytes: bytes, message: str) -> None:
    """åœ¨ GitHub å°ˆæ¡ˆä¸­å»ºç«‹/æ›´æ–°æª”æ¡ˆå…§å®¹ã€‚"""
    if not (GITHUB_REPO and GITHUB_BRANCH and GITHUB_TOKEN):
        raise RuntimeError("ç¼ºå°‘ GitHub è¨­å®šæˆ– Tokenï¼Œç„¡æ³•å¯«å…¥ GitHubã€‚")
    url = f"https://api.github.com/repos/{GITHUB_REPO}/contents/{path_in_repo}"
    sha = gh_get_file_sha(path_in_repo)
    payload = {
        "message": message,
        "content": base64.b64encode(content_bytes).decode("utf-8"),
        "branch": GITHUB_BRANCH,
    }
    if sha:
        payload["sha"] = sha
    r = requests.put(url, headers=_gh_headers(), json=payload, timeout=15)
    r.raise_for_status()

# ========= åŸºæœ¬è¨­å®š =========
st.set_page_config(page_title="æœˆæœƒä¸‹åˆèŒ¶ç·šä¸Šé»é¤", page_icon="ğŸ±", layout="wide")
TZ = ZoneInfo("Asia/Taipei")

# æˆªå–®ï¼ˆå¯ç”¨ "18:00" æˆ– "2025/10/14, 18:00" / "2025-10-14, 18:00"ï¼‰
CUTOFF = "2025/10/14 12:30"

# å·¥ä½œè¡¨åç¨±ï¼ˆåƒ…ç”¨æ–¼ä¸‹è¼‰çš„ Excel æª”å/å·¥ä½œè¡¨åï¼‰
ORDERS_WS = "Orders"
SUMMARY_WS = "Summary"

BASE = Path(".")
DATA_DIR = BASE / "data"
IMG_DIR = BASE /  "menus"   # æ”¾å…©å¼µèœå–®åœ–ç‰‡
DATA_DIR.mkdir(parents=True, exist_ok=True)
IMG_DIR.mkdir(parents=True, exist_ok=True)

# ========= è®€å¯«ï¼šGitHub å„ªå…ˆï¼Œç¼ºè¨­å®šå‰‡é€€å›æœ¬åœ° =========
ORDERS_PATH_IN_REPO = "data/orders.csv"
ORDER_ITEMS_PATH_IN_REPO = "data/order_items.csv"
LOCAL_ORDERS_CSV = DATA_DIR / "orders.csv"
LOCAL_ORDER_ITEMS_CSV = DATA_DIR / "order_items.csv"

def _github_configured() -> bool:
    return bool(GITHUB_REPO and GITHUB_BRANCH and GITHUB_TOKEN)

def load_orders():
    # å„ªå…ˆå¾ GitHub è®€å–
    if GITHUB_REPO:
        try:
            return gh_read_csv(ORDERS_PATH_IN_REPO)
        except Exception:
            pass
    # é€€å›æœ¬åœ°æª”æ¡ˆ
    if LOCAL_ORDERS_CSV.exists():
        return pd.read_csv(LOCAL_ORDERS_CSV, dtype=str)
    return pd.DataFrame(columns=["order_id","user_name","note","created_at","is_paid"])

def load_order_items():
    # å„ªå…ˆå¾ GitHub è®€å–
    if GITHUB_REPO:
        try:
            df = gh_read_csv(ORDER_ITEMS_PATH_IN_REPO).fillna("")
            if "qty" in df.columns:
                df["qty"] = pd.to_numeric(df["qty"], errors="coerce").fillna(0).astype(int)
            if "unit_price" in df.columns:
                df["unit_price"] = pd.to_numeric(df["unit_price"], errors="coerce").fillna(0.0)
            return df
        except Exception:
            pass
    # é€€å›æœ¬åœ°æª”æ¡ˆ
    if LOCAL_ORDER_ITEMS_CSV.exists():
        df = pd.read_csv(LOCAL_ORDER_ITEMS_CSV, dtype=str).fillna("")
        if "qty" in df.columns:
            df["qty"] = pd.to_numeric(df["qty"], errors="coerce").fillna(0).astype(int)
        if "unit_price" in df.columns:
            df["unit_price"] = pd.to_numeric(df["unit_price"], errors="coerce").fillna(0.0)
        return df
    return pd.DataFrame(columns=["order_id","item_name","qty","unit_price"])

def save_orders(df: pd.DataFrame):
    if _github_configured():
        gh_upsert_file(
            ORDERS_PATH_IN_REPO,
            df.to_csv(index=False).encode("utf-8"),
            message="chore: update orders.csv via Streamlit app",
        )
    else:
        df.to_csv(LOCAL_ORDERS_CSV, index=False)

def save_order_items(df: pd.DataFrame):
    if _github_configured():
        gh_upsert_file(
            ORDER_ITEMS_PATH_IN_REPO,
            df.to_csv(index=False).encode("utf-8"),
            message="chore: update order_items.csv via Streamlit app",
        )
    else:
        df.to_csv(LOCAL_ORDER_ITEMS_CSV, index=False)

# ========= æˆªå–®åˆ¤å®š =========
def cutoff_state(cutoff_str: str):
    """
    å›å‚³ (passed, msg)
    passed: True=å·²æˆªå–®ï¼›False=ä»å¯ä¸‹å–®
    æ”¯æ´ 'HH:MM' æˆ– 'YYYY/MM/DD, %H:%M' / 'YYYY-%m-%d, %H:%M' / 'YYYY/MM/DD %H:%M'
    """
    now = datetime.now(TZ)
    try:
        if any(ch in cutoff_str for ch in ["/", "-", "å¹´", "æœˆ"]):
            for fmt in ["%Y/%m/%d, %H:%M", "%Y-%m-%d, %H:%M", "%Y/%m/%d %H:%M"]:
                try:
                    cutoff = datetime.strptime(cutoff_str.strip(), fmt).replace(tzinfo=TZ)
                    break
                except ValueError:
                    continue
            else:
                raise ValueError("cutoff_str format error")
        else:
            hh, mm = map(int, cutoff_str.strip().split(":"))
            cutoff = now.replace(hour=hh, minute=mm, second=0, microsecond=0)
    except Exception:
        cutoff = now.replace(hour=18, minute=0, second=0, microsecond=0)

    if now >= cutoff:
        return True, f"å·²æˆªå–®ï¼ˆ{cutoff.strftime('%Y/%m/%d %H:%M')}ï¼‰"

    left = cutoff - now
    d = left.days
    h = left.seconds // 3600
    m = (left.seconds % 3600) // 60
    return False, f"è·é›¢æˆªå–®å‰©é¤˜ {d} å¤© {h} å°æ™‚ {m} åˆ†ï¼ˆ{cutoff.strftime('%Y/%m/%d %H:%M')}ï¼‰"

# ï¼ˆå·²ç°¡åŒ–ï¼‰ç§»é™¤ Excel å¯«å…¥ç£ç¢Ÿçš„åŠŸèƒ½ï¼Œåƒ…ä¿ç•™å³æ™‚ä¸‹è¼‰

# ========= å´é‚Šæ¬„ï¼šä¸Šå‚³èœå–®åœ– =========
st.sidebar.title("ğŸ½ï¸ ç·šä¸Šé»é¤")
with st.sidebar.expander("èœå–®åœ–ç‰‡ç¶­è­·", expanded=False):
    files = st.file_uploader("ä¸Šå‚³åœ–ç‰‡ï¼ˆjpg/png/jpegï¼‰", type=["jpg","jpeg","png"], accept_multiple_files=True)
    if files:
        for f in files:
            Image.open(f).save(IMG_DIR / f"{uuid.uuid4().hex}.png")
        st.success("åœ–ç‰‡å·²ä¸Šå‚³ï¼é‡æ–°æ•´ç†å³å¯çœ‹åˆ°ã€‚")

mode = st.sidebar.radio("æ¨¡å¼ / Mode", ["é»é¤æ¨¡å¼", "ç¢ºèªæ¨¡å¼"])

# ========= å‰å°é»é¤ =========
if mode == "é»é¤æ¨¡å¼":
    st.title("ğŸ“‹ ç·šä¸Šé»é¤")
    passed, msg = cutoff_state(CUTOFF)
    st.info(msg)

    # é¡¯ç¤ºå…©å¼µèœå–®ï¼ˆå–å‰å…©å¼µï¼‰ï¼Œç°¡åŒ–ç‚ºç›´æ¥é¡¯ç¤º
    imgs = sorted([p for p in IMG_DIR.glob("*") if p.suffix.lower() in [".jpg", ".jpeg", ".png"]])
    show_imgs = imgs[:2]

    st.subheader("èœå–®")
    if not show_imgs:
        st.warning("å°šæœªä¸Šå‚³èœå–®åœ–ç‰‡ï¼ˆå´é‚Šæ¬„å¯ä¸Šå‚³ï¼‰ã€‚")
    else:
        cols = st.columns(2)
        for i, p in enumerate(show_imgs):
            with cols[i % 2]:
                st.image(str(p), use_container_width=True, caption=f"èœå–® {i+1}")
    st.divider()

    # ====== å¡«å¯«é¤é»ï¼ˆæ”¹ç‚º Data Editorï¼Œç°¡æ½”å¥½ç”¨ï¼‰ ======
    st.subheader("å¡«å¯«é¤é»")
    default_df = pd.DataFrame([
        {"item_name": "", "qty": 0, "unit_price": 0.0},
        {"item_name": "", "qty": 0, "unit_price": 0.0},
    ])

    with st.form("order_form", clear_on_submit=False):
        edited_df = st.data_editor(
            default_df,
            num_rows="dynamic",
            use_container_width=True,
            hide_index=True,
            disabled=passed,
            column_config={
                "item_name": st.column_config.TextColumn("å“é …åç¨±"),
                "qty": st.column_config.NumberColumn("æ•¸é‡", min_value=0, step=1),
                "unit_price": st.column_config.NumberColumn("å–®åƒ¹", min_value=0.0, step=1.0),
            },
            key="editor_table",
        )

        safe_df = edited_df.copy() if isinstance(edited_df, pd.DataFrame) else default_df.copy()
        for col in ["qty", "unit_price"]:
            if col in safe_df.columns:
                safe_df[col] = pd.to_numeric(safe_df[col], errors="coerce").fillna(0)
        total = int((safe_df.get("qty", 0) * safe_df.get("unit_price", 0)).sum())

        st.markdown(f"### ç¸½è¨ˆï¼š${total}")
        name = st.text_input("å§“å/æš±ç¨±", st.session_state.get("name_single_store", ""), disabled=passed)
        note = st.text_input("å‚™è¨»ï¼ˆä¾‹å¦‚ä¸è¦é¦™èœï¼é£²å“ç³–å†°ï¼‰", st.session_state.get("note_single_store", ""), disabled=passed)
        submitted = st.form_submit_button("é€å‡ºè¨‚å–®", type="primary", use_container_width=True, disabled=passed)

    # å›å­˜å§“å/å‚™è¨»åˆ°å›ºå®šéµï¼ˆè®“ä¸‹æ¬¡é¡¯ç¤ºé è¨­å€¼ï¼‰
    st.session_state["name_single_store"] = name if 'name' in locals() else st.session_state.get("name_single_store", "")
    st.session_state["note_single_store"] = note if 'note' in locals() else st.session_state.get("note_single_store", "")

    if submitted:
        if not name.strip():
            st.error("è«‹è¼¸å…¥å§“å/æš±ç¨±"); st.stop()

        valid = safe_df[(safe_df.get("item_name", "").astype(str).str.strip() != "") & (safe_df.get("qty", 0) > 0)].copy()
        if valid.empty:
            st.error("è«‹è‡³å°‘å¡«ä¸€åˆ—æœ‰æ•ˆé¤é»"); st.stop()

        orders_df = load_orders()
        items_df  = load_order_items()
        oid = uuid.uuid4().hex[:12]
        now = datetime.now(TZ).strftime("%Y-%m-%d %H:%M:%S")

        orders_df = pd.concat([orders_df, pd.DataFrame([{
            "order_id": oid,
            "user_name": name.strip(),
            "note": note.strip(),
            "created_at": now,
            "is_paid": "å¦",
        }])], ignore_index=True)

        valid["order_id"] = oid
        valid["item_name"] = valid["item_name"].astype(str).str.strip()
        valid["qty"] = pd.to_numeric(valid["qty"], errors="coerce").fillna(0).astype(int)
        valid["unit_price"] = pd.to_numeric(valid["unit_price"], errors="coerce").fillna(0.0)
        items_df = pd.concat([items_df, valid.loc[:, ["order_id","item_name","qty","unit_price"]]], ignore_index=True)

        try:
            save_orders(orders_df)
            save_order_items(items_df)
            st.success(f"è¨‚å–®é€å‡ºæˆåŠŸï¼ç·¨è™Ÿï¼š{oid}")
            st.balloons()
        except Exception as e:
            st.error(f"è¨‚å–®å·²æš«å­˜åœ¨æœ¬åœ°ï¼Œä½†æ¨é€åˆ° GitHub å¤±æ•—ï¼š{e}")

# ========= ç®¡ç†è€…æ¨¡å¼ =========
else:
    st.title("ğŸ”§ ç¢ºèªæ¨¡å¼")

    orders = load_orders()
    items  = load_order_items()

    if orders.empty:
        st.info("å°šç„¡è¨‚å–®")
        st.stop()

    # å½™ç¸½ï¼ˆå“é … + å–®åƒ¹ï¼‰
    agg = items.groupby(["item_name","unit_price"], as_index=False).agg(total_qty=("qty","sum"))
    agg["amount"] = (agg["total_qty"] * agg["unit_price"]).astype(int)

    st.subheader("å“é …å½™ç¸½")
    st.dataframe(
        agg.rename(columns={"item_name":"å“é …","unit_price":"å–®åƒ¹","total_qty":"æ•¸é‡","amount":"é‡‘é¡"}),
        use_container_width=True
    )
    st.markdown(f"**ç¸½é‡‘é¡ï¼š** ${int(agg['amount'].sum())}")

    # è¨‚å–®åˆ—è¡¨ + åˆ‡æ›æ”¶æ¬¾
    order_total = items.groupby("order_id", as_index=False).apply(
        lambda df: pd.Series({"order_total": int((df["qty"]*df["unit_price"]).sum())})
    ).reset_index(drop=True)
    orders = orders.merge(order_total, on="order_id", how="left").fillna({"order_total":0})
    orders = orders.sort_values("created_at", ascending=False)

    st.subheader("è¨‚å–®åˆ—è¡¨")
    for _, od in orders.iterrows():
        with st.container(border=True):
            st.markdown(f"**è¨‚å–® {od['order_id']}**ï½œ{od['created_at']}ï½œ{od['user_name']}ï½œé‡‘é¡ ${int(od['order_total'])}")
            if str(od["note"]).strip():
                st.caption(f"å‚™è¨»ï¼š{od['note']}")
            c1, c2 = st.columns([1,1])
            with c1:
                st.write(f"å·²æ”¶æ¬¾ï¼š{od['is_paid']}")
            with c2:
                if st.button(f"åˆ‡æ›æ”¶æ¬¾ï¼ˆ{od['order_id']}ï¼‰", key=f"pay_{od['order_id']}"):
                    all_orders = load_orders()
                    mask = (all_orders["order_id"] == od["order_id"])
                    cur = all_orders.loc[mask, "is_paid"].iloc[0]
                    all_orders.loc[mask, "is_paid"] = "å¦" if cur=="æ˜¯" else "æ˜¯"
                    save_orders(all_orders); st.success("å·²æ›´æ–°æ”¶æ¬¾ç‹€æ…‹"); st.rerun()

    # ï¼ˆå·²ç°¡åŒ–ï¼‰ç§»é™¤ã€Œå¯«å…¥ Excel æª”æ¡ˆã€åŠŸèƒ½

    # å³æ™‚ç”Ÿæˆä¸¦ä¸‹è¼‰ï¼ˆä¸ä¾è³´ç£ç¢Ÿï¼‰
    st.divider()
    st.subheader("ä¸‹è¼‰ Excel")
    st.caption("åŒ…å« Ordersï¼ˆé€å–®ï¼‰èˆ‡ Summaryï¼ˆå½™ç¸½ï¼‰å…©å¼µå·¥ä½œè¡¨ã€‚")

    # çµ„ã€Œæ˜ç´°ã€èˆ‡ã€Œç¸½é¡ã€æ¬„ä½
    detail = items.groupby("order_id").apply(
        lambda d: "; ".join([f"{r['item_name']}x{int(r['qty'])}@{int(r['unit_price'])}" for _, r in d.iterrows()])
    ).reset_index(name="æ˜ç´°")
    total = items.groupby("order_id").apply(
        lambda d: int((d["qty"]*d["unit_price"]).sum())
    ).reset_index(name="ç¸½é¡")

    export_orders = (
        orders.merge(detail, on="order_id", how="left")
              .merge(total,  on="order_id", how="left")
              .loc[:, ["created_at","order_id","user_name","æ˜ç´°","ç¸½é¡","note","is_paid"]]
              .rename(columns={"created_at":"æ™‚é–“","order_id":"è¨‚å–®ID","user_name":"å§“å","note":"å‚™è¨»","is_paid":"å·²æ”¶æ¬¾"})
    )

    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        export_orders.to_excel(writer, sheet_name=ORDERS_WS, index=False)
        agg_out = agg.rename(columns={"item_name":"å“é …","unit_price":"å–®åƒ¹","total_qty":"æ•¸é‡","amount":"é‡‘é¡"})
        agg_out.to_excel(writer, sheet_name=SUMMARY_WS, index=False)
    buf.seek(0)

    st.download_button(
        "â¬‡ï¸ ä¸‹è¼‰ Excelï¼ˆå³æ™‚ç”¢ç”Ÿï¼‰",
        data=buf.getvalue(),
        file_name=f"orders_{datetime.now(TZ):%Y%m%d}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True
    )




